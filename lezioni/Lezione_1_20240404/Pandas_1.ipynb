{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7ff05fa0",
   "metadata": {},
   "source": [
    "# Pandas 1"
   ]
  },
  {
   "cell_type": "code",
   "id": "a484a50c",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "6ea3d8d3",
   "metadata": {},
   "source": [
    "### Creare una serie\n",
    "Proviamo a creare una serie pandas utilizzando dei numeri casuali generati con la libreria numpy. <br>\n",
    "Utilizziamo la proprietà random, con cui è possibile generare numeri pseudocasuali: specificando il medesimo seed è possibile generare sempre gli stessi numeri pseudocasuali (in questo caso utilizziamo sempre \"1\" come seed)."
   ]
  },
  {
   "cell_type": "code",
   "id": "9c834e57",
   "metadata": {},
   "source": [
    "np.random.seed(1)\n",
    "s = pd.Series(np.random.randn(100))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "389118a6",
   "metadata": {},
   "source": [
    "s.head(21) # restituisce i primi 21 valori della serie (da 0 a 20)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "541c1430",
   "metadata": {},
   "source": [
    "s[2] # restituisce il terzo elemento della serie (le serie sono indicizzate a partire da 0)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c641cede",
   "metadata": {},
   "source": [
    "s[[2,5,20]] # è possibile passare tra le quadre un array di posizioni per far restituire soltanto le posizioni di interesse"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "61434f61",
   "metadata": {},
   "source": [
    "s[3:8] # restituisce gli elementi compresi tra le posizioni specificate (estremo finale escluso)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "dcf5ac6f",
   "metadata": {},
   "source": [
    "s.tail(10) # restituisce gli ultimi 10 elementi della serie"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "519d6150",
   "metadata": {},
   "source": [
    "s.index # proprietà che permette di conoscere come la serie è indicizzata"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d5d3b115",
   "metadata": {},
   "source": [
    "s.values # proprietà che elenca i valori della serie in un array"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "69e1a402",
   "metadata": {},
   "source": [
    "È possibile decidiere di indicizzare una serie in maniera diversa da quella default"
   ]
  },
  {
   "cell_type": "code",
   "id": "f2892c15",
   "metadata": {},
   "source": [
    "s2 = pd.Series([1,2,3,4], index = ['a', 'b', 'c', 'd'])\n",
    "s2"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "dc9ccf7c",
   "metadata": {},
   "source": [
    "Anche a partire da un dizionario chiave:valore può essere creata una serie, in cui la chiave di ciascun elemento del dizionario corrisponderà all'indice di tale elemento nella serie"
   ]
  },
  {
   "cell_type": "code",
   "id": "878ce824",
   "metadata": {},
   "source": [
    "\n",
    "s3 = pd.Series({'a':1, 'b':2, 'c':3, 'd':4})"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "af286ee2",
   "metadata": {},
   "source": [
    "Il numero di elementi di una serie può essere determinato utilizzando la funzione `len()`."
   ]
  },
  {
   "cell_type": "code",
   "id": "4c056163",
   "metadata": {},
   "source": [
    "s = pd.Series([10,0,1,1,2,3,4,5,6,np.nan])\n",
    "s"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3dba4f89",
   "metadata": {},
   "source": [
    "len(s)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "bb1386ed",
   "metadata": {},
   "source": [
    "Un altro modo per determinare la dimensione di una serie è utilizzare la proprietà `shape` che restituisce una tupla con le dimensioni, numero righe e numero colonne.<br>\n",
    "Nel caso di una serie avente una sola dimensione, si ottiene una tupla contenente un solo valore."
   ]
  },
  {
   "cell_type": "code",
   "id": "f74c9c29",
   "metadata": {},
   "source": [
    "s.shape"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2bd55636",
   "metadata": {},
   "source": [
    "Nella serie di esempio abbiamo un valore che non è un numero (np.nan): per contare solo i valori numerici si utilizza il metodo `count()`."
   ]
  },
  {
   "cell_type": "code",
   "id": "e0d5ecbf",
   "metadata": {},
   "source": [
    "s.count()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "49726aec",
   "metadata": {},
   "source": [
    "Per conoscere invece i valori unici di una serie si utilizza il metodo `unique()`."
   ]
  },
  {
   "cell_type": "code",
   "id": "2a60ee55",
   "metadata": {},
   "source": [
    "s.unique()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "7fa25c80",
   "metadata": {},
   "source": [
    "E per contare invece il numero di volte in cui appaiono tali valori unici nella serie si usa il metodo `value_counts()`, il quale restituisce i valori già ordinati in ordine decrescente."
   ]
  },
  {
   "cell_type": "code",
   "id": "ce358c1e",
   "metadata": {},
   "source": [
    "s.value_counts()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e22bd1ba",
   "metadata": {},
   "source": [
    "__NB__: una differenza fondamentale fra gli array di Numpy e le serie di Pandas è che le serie sono in grado di effettuare l'allineamento automatico sulla base dell'etichette poste come indici; questo significa che gli elementi appartenenti a due diverse serie vengono fatti corrispondere sulla base dell'etichetta, non sulla base della sola posizione come invece avviene negli array Numpy."
   ]
  },
  {
   "cell_type": "code",
   "id": "c512be88",
   "metadata": {},
   "source": [
    "s3 = pd.Series([1,2,3,4], index = ['a','b','c','d'])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a269d494",
   "metadata": {},
   "source": [
    "s3"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9745a7e3",
   "metadata": {},
   "source": [
    "s4 = pd.Series([4,3,2,1], index = ['d','c','b','a'])\n",
    "s4"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c8b78807",
   "metadata": {},
   "source": [
    "Avendo gli stessi indici è possibile sommare le due serie, ottenendo una nuova serie contenente in ciascun elemento la somma degli elementi delle due serie sommate. <br>\n",
    "__NB__: nonostante le etichette siano state assegnate agli indici in un ordine differente nelle due serie, la somma avviene comunque facendo combaciare tali etichette."
   ]
  },
  {
   "cell_type": "code",
   "id": "a3fb0a28",
   "metadata": {},
   "source": [
    "s3 + s4"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "9581030b",
   "metadata": {},
   "source": [
    "Negli array Numpy invece, l'operazione viene effettuata solo sulla base della posizione: sommare due array significa quindi ottenere un nuovo array dove ciascun elemento è dato dalla somma degli elementi posti in nella medesima posizione nei due array."
   ]
  },
  {
   "cell_type": "code",
   "id": "77b9f3cc",
   "metadata": {},
   "source": [
    "np3 = np.array([1,2,3,4])\n",
    "np4 = np.array([4,3,2,1])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "55cb63d4",
   "metadata": {},
   "source": [
    "np3 + np4"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d01b23a0",
   "metadata": {},
   "source": [
    "### Creare un dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4c23f5",
   "metadata": {},
   "source": [
    "Un DataFrame può essere creato combinando diversi array Numpy."
   ]
  },
  {
   "cell_type": "code",
   "id": "f8c33fa4",
   "metadata": {},
   "source": [
    "pd.DataFrame(np.array([[10,11],[20,21],[30,31]]))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "7daabb3d",
   "metadata": {},
   "source": [
    "Se non si specificano i valori degli indici e i nomi delle colonne, Pandas utilizza numeri interi."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ecac5a",
   "metadata": {},
   "source": [
    "Un DataFrame può anche essere creato combinando diverse serie Pandas."
   ]
  },
  {
   "cell_type": "code",
   "id": "a5b7e75f",
   "metadata": {},
   "source": [
    "df1 = pd.DataFrame([pd.Series(np.arange(10,15)),\n",
    "                   pd.Series(np.arange(15,20))])\n",
    "df1"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f6b8e296",
   "metadata": {},
   "source": [
    "Per conoscere le dimensioni di un DataFrame è possibile nuovamente fare uso della proprietà `shape`. <br>\n",
    "__NB__: un DataFrame ha solo due dimensioni, quindi `shape` restituisce sempre una tupla del tipo (numero_righe, numero_colonne)."
   ]
  },
  {
   "cell_type": "code",
   "id": "14677a18",
   "metadata": {},
   "source": [
    "df1.shape"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a8726c94",
   "metadata": {},
   "source": [
    "Per associare un nome alle colonne si fa uso del parametro `columns`."
   ]
  },
  {
   "cell_type": "code",
   "id": "994aaa2c",
   "metadata": {},
   "source": [
    "df = pd.DataFrame(np.array([[10,11],[20,21],[30,31]]), columns = ['a','b'])\n",
    "df"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "aaad8815",
   "metadata": {},
   "source": [
    "E per conoscere il nome delle colonne di un DataFrame si usa l'omonima proprietà."
   ]
  },
  {
   "cell_type": "code",
   "id": "fe11ad16",
   "metadata": {},
   "source": [
    "df.columns"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "db531e76",
   "metadata": {},
   "source": [
    "__NB__: è possibile sovrascrivere i nomi delle colonne di un DataFrame assegnando i nuovi nomi alla sua proprietà `columns`."
   ]
  },
  {
   "cell_type": "code",
   "id": "d8960625",
   "metadata": {},
   "source": [
    "df.columns = ['c1', 'c2']\n",
    "df"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d499717e",
   "metadata": {},
   "source": [
    "__NB__: vale lo stesso identico discorso per le righe, questa volta usando la proprietà `index`."
   ]
  },
  {
   "cell_type": "code",
   "id": "c9cec395",
   "metadata": {},
   "source": [
    "df.index = ['r1', 'r2', 'r3']\n",
    "df"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f5ae1927",
   "metadata": {},
   "source": [
    "La proprietà `index` serve anche per conoscere i nomi degli indici del DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "id": "c250cde4",
   "metadata": {},
   "source": [
    "df.index"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "51135c10",
   "metadata": {},
   "source": [
    "### Esempi\n",
    "\n",
    "Creiamo un DataFrame partendo da un file csv che contiene dati sulle 500 società che costituiscono l'indice della borsa americana Standard & Poors 500.<br>\n",
    "Con il parametro `index_col` specifichiamo quale colonna del file csv dovrà rappresentare l'indice del DataFrame che stiamo creando: in questo caso scegliamo la colonna \"Symbol\", che contiene i tickers dei titoli."
   ]
  },
  {
   "cell_type": "code",
   "id": "024d3f21",
   "metadata": {},
   "source": [
    "sp500 = pd.read_csv(\"sp500.csv\", index_col='Symbol')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "62746541",
   "metadata": {},
   "source": [
    "sp500.shape # dimensioni del dataframe: 500 righe e 14 colonne"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "258faf12",
   "metadata": {},
   "source": [
    "sp500.index # indici del dataframe, ovvero i tickers dei titoli"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a6ea1c2b",
   "metadata": {},
   "source": [
    "sp500.columns"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a32fc0f9",
   "metadata": {},
   "source": [
    "Per ora ci interessano solo alcune colonne: per filtrarle possiamo agire in due modi. <br>\n",
    "Il primo modo è leggere il file csv indicando quali colonne ci interessano con il parametro `usecols`."
   ]
  },
  {
   "cell_type": "code",
   "id": "f936235d",
   "metadata": {},
   "source": [
    "sp500_1 = pd.read_csv(\"sp500.csv\", index_col='Symbol', usecols = [0, 2, 3])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c5fa2cff",
   "metadata": {},
   "source": [
    "sp500_1.head(10)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "raw",
   "id": "f54c3348",
   "metadata": {},
   "source": [
    "Il secondo modo è passare una lista di colonne al DataFrame e farci restituire il DataFrame composto dalle sole colonne di nostro interesse."
   ]
  },
  {
   "cell_type": "code",
   "id": "8cc7b3b5",
   "metadata": {},
   "source": [
    "sp500_2 = sp500[['Sector','Price','Book Value']]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8fbf64c9",
   "metadata": {},
   "source": [
    "sp500_2.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "6617bda16fb24754",
   "metadata": {},
   "source": [
    "Possiamo anche usare la proprietà `iloc` che consente di specificare quali righe e colonne si vuole selezionare all'interno del DataFrame: nel nostro caso vogliamo selezionare tutte le righe (e specifichiamo `:` alla proprietà proprio per dire questo) e vogliamo selezionare le sole colonne nelle posizioni 1, 2 e 6."
   ]
  },
  {
   "cell_type": "code",
   "id": "a09f64dd",
   "metadata": {},
   "source": [
    "sp500_3 = sp500.iloc[:,[1,2,6]] # la sintassi è iloc[righe, colonne]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "63c854a8",
   "metadata": {},
   "source": [
    "sp500_3"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "13255046",
   "metadata": {},
   "source": [
    "__NB__: i DataFrame creati fino a questo momento non sono nuovi DataFrame, ma sono soltanto viste che fanno riferimento a quello originale; per creare effettivamente un nuovo DataFrame occorre invocare il metodo `copy()`."
   ]
  },
  {
   "cell_type": "code",
   "id": "0ea00192",
   "metadata": {},
   "source": [
    "sp500_4 = sp500.iloc[:,[1,2,6]].copy()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b0b01d06",
   "metadata": {},
   "source": [
    "Le colonne di un DataFrame di Pandas altro non sono che delle serie, motivo per cui è possibile estrapolare una serie a partire da una colonna di un DataFrame (questo però è possibile soltanto se il nome della colonna è privo di spazi)."
   ]
  },
  {
   "cell_type": "code",
   "id": "6319edd9",
   "metadata": {},
   "source": [
    "sp500.Price"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9cbe0866",
   "metadata": {},
   "source": [
    "sp500.BookValue # errore, perché il nome della colonna è Book Value (con lo spazio)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "0f826603",
   "metadata": {},
   "source": [
    "### Selezionare righe in un DataFrame\n",
    "\n",
    "Per selezionare determinate righe in un DataFrame ci sono tre modi:\n",
    "- individuare una fetta di DataFrame (\"slicing\") con []\n",
    "- cercare gli elementi sulla base dell'etichetta o del numero indice con gli operatori `loc` e `iloc`\n",
    "- ricerca scalare con gli operatori `at` e `iat`\n",
    "\n",
    "L'utilizzo dell'operatore [] va bene per selezionare elementi di una serie, tuttavia è sconsigliato (fatto salvo per casi particolari) per selezionare righe di un DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1eb03a",
   "metadata": {},
   "source": "Selezione delle prime tre righe utilizzando l'operatore []:"
  },
  {
   "cell_type": "code",
   "id": "ed15f5ad",
   "metadata": {},
   "source": "sp500_1[:3] # la sintassi è [start:end] dove l'indice di inizio è omesso in questo caso (di default si parte da indice 0)",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Selezione delle righe che vanno da XYL a YUM utilizzando l'operatore []:",
   "id": "8f2be2c551a328c8"
  },
  {
   "cell_type": "code",
   "id": "702d2064",
   "metadata": {},
   "source": [
    "sp500_1['XYL':'YUM']"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "22bdf53e",
   "metadata": {},
   "source": [
    "Selezione utilizzando `loc[]` e `iloc[]`:\n",
    "- `loc` basa la selezione sull'etichetta \n",
    "- `iloc` basa la selezione sull'indice (di posizione)"
   ]
  },
  {
   "cell_type": "code",
   "id": "b50c178b",
   "metadata": {},
   "source": "sp500_1.loc['MMM']",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c80adcec",
   "metadata": {},
   "source": [
    "sp500_1.loc[['MMM','MSFT']]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "__NB__: scrivendo ad esempio `sp500_1.loc[3]` si sta chiedendo di selezionare la riga avente come _etichetta_ 3, non la riga in _posizione_ 3.",
   "id": "ad91279033787660"
  },
  {
   "cell_type": "code",
   "id": "c023c267",
   "metadata": {},
   "source": [
    "sp500_1.iloc[[0,5]]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "571e79db",
   "metadata": {},
   "source": [
    "sp500_1.iloc[0:5]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "57db5f04",
   "metadata": {},
   "source": "Con il metodo `index.get_loc` si può sapere qual è il valore dell'indice (di posizione) associato a una specifica etichetta."
  },
  {
   "cell_type": "code",
   "id": "ad947bef",
   "metadata": {},
   "source": [
    "sp500_1.index.get_loc('MSFT')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a2660614",
   "metadata": {},
   "source": [
    "i1 = sp500_1.index.get_loc('MMM')\n",
    "i2 = sp500_1.index.get_loc('A')\n",
    "i1, i2"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e093e081",
   "metadata": {},
   "source": [
    "sp500_1.iloc[[i1,i2]]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "3136a9c2",
   "metadata": {},
   "source": [
    "Ricerca scalare utilizzando `at[]` e `iat[]`:\n",
    "- `at[]` effettua la ricerca sulla base delle etichette di riga e colonna specificate\n",
    "- `iat[]` effettua la ricerca sulla base degli indici numerici di posizione di riga e colonna specificati"
   ]
  },
  {
   "cell_type": "code",
   "id": "ded2ee9d",
   "metadata": {},
   "source": [
    "sp500_1.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4c044b00",
   "metadata": {},
   "source": [
    "sp500_1.at['MMM', 'Sector']"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "668874b4",
   "metadata": {},
   "source": [
    "sp500_1.iat[0,1]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "8e3a2e60",
   "metadata": {},
   "source": "C'è anche la possibilità di effettuare una selezione che comprenda soltanto le righe che soddisfano una determinata condizione booleana."
  },
  {
   "cell_type": "code",
   "id": "404d5874",
   "metadata": {},
   "source": [
    "sp500_1[sp500_1.Price < 20]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "0e6be36e",
   "metadata": {},
   "source": "Le ricerche poi possono diventare anche più dettagliate, combinando condizioni booleani e altre tipologie di selezione."
  },
  {
   "cell_type": "code",
   "id": "a23d167c",
   "metadata": {},
   "source": [
    "sp500_1[(sp500_1.Price < 20) & (sp500_1.Price > 10)][['Sector','Price']]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "43884223",
   "metadata": {},
   "source": [
    "### Operazioni su DataFrame\n",
    "\n",
    "Le operazioni aritmetiche che coinvolgono il DataFrame ed uno scalare vengono effettuate su tutte le celle del DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "id": "ff4ff4bf",
   "metadata": {},
   "source": [
    "np.random.seed(123456)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7ce219ee",
   "metadata": {},
   "source": [
    "df = pd.DataFrame(np.random.randn(5,4), columns = ['A','B','C','D'])\n",
    "df"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2a2d3fe2",
   "metadata": {},
   "source": "df*2 # ogni valore presente nelle celle del DataFrame viene moltiplicato per 2",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "cf75464b",
   "metadata": {},
   "source": "Si possono effettuare operazioni sul DataFrame a partire dai valori contenuti in una sua riga."
  },
  {
   "cell_type": "code",
   "id": "5cd1c783",
   "metadata": {},
   "source": "df - df.iloc[0] # ad ogni riga del DataFrame sottrai i valori contenuti nella prima riga (facendo corrispondere le celle)",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a1d23d46",
   "metadata": {},
   "source": "Nel caso in cui si voglia effettuare operazioni a partire dai valori contenuti in una porzione del DataFrame, è possibile creare un nuovo DataFrame che sia un \"sotto-dataframe\" di quello originale: per farlo, effettuiamo la selezione delle righe e colonne di interesse mediante l'operatore []."
  },
  {
   "cell_type": "code",
   "id": "925a670e",
   "metadata": {},
   "source": [
    "subframe = df[1:4][['B','C']]\n",
    "subframe"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2db7fb25",
   "metadata": {},
   "source": "df - subframe # l'operazione viene effettuata solo dove ci sono valori da sottrarre, altrimenti rerstituisce NaN",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "__NB__: il DataFrame `df` ha dimensioni 5x4, mentre il DataFrame `subframe` ha dimensioni 3x2; questo implica che per alcune celle di `df` non è presente il corrispondente valore di `subframe` da sottrarre, quindi il risultato è un DataFrame 5x4 in cui le celle dove non è stato possibile effettuare l'operazione contengono NaN (Not a Number).",
   "id": "88cb7f78b01182e"
  },
  {
   "cell_type": "markdown",
   "id": "af41a0dd",
   "metadata": {},
   "source": "Si possono anche effettuare operazioni che coinvolgono intere colonne."
  },
  {
   "cell_type": "code",
   "id": "a29175dd",
   "metadata": {},
   "source": [
    "a_col = df['A']"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ea2e7404",
   "metadata": {},
   "source": "df.sub(a_col, axis=0) # sottrae il contenuto della colonna 'A' a tutte le altre colonne del DataFrame",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "__NB__: il parametro `axis` consente di decidere lungo quale asse eseguire l'operazione: axis=0 significa \"esegui l'operazione lungo l'asse delle righe\", mentre axis=1 significa \"esegui l'operazione lungo l'asse delle colonne\". <br>\n",
    "__PER CAPIRE__: con axis=0 agisco sulle colonne, con axis=1 agisco sulle righe."
   ],
   "id": "50c104f17fbc7cba"
  },
  {
   "cell_type": "markdown",
   "id": "376470c6",
   "metadata": {},
   "source": [
    "### Reindicizzazione\n",
    "Reindicizzare un DataFrame significa applicare delle modifiche alle etichette delle sue righe e/o colonne.\n",
    "\n",
    "Il processo di reindicizzazione:\n",
    "- riordina i dati per farli corrispondere a un nuovo insieme di etichette fornito\n",
    "- inserisce NaN laddove viene inserita una nuova etichetta e quindi mancano dei dati\n",
    "- inserisce NaN laddove mancano alcuni dati in celle appartenenti a etichette già esistenti"
   ]
  },
  {
   "cell_type": "code",
   "id": "4f5b1338",
   "metadata": {},
   "source": [
    "np.random.seed(1)\n",
    "s = pd.Series(np.random.randn(5))\n",
    "s.index = ['a','b','c','d','e']\n",
    "s"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c9afa3c6",
   "metadata": {},
   "source": "Il metodo `reindex()` permette di effettuare la reindicizzazione di una serie: utilizzandolo si può creare una nuova serie di lunghezza diversa."
  },
  {
   "cell_type": "code",
   "id": "c47fd35b",
   "metadata": {},
   "source": [
    "s2 = s.reindex(['a','c','e','g']) # g è una nuova etichetta, ad essa corrisponderà valore NaN\n",
    "s2"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "74b9bd4b",
   "metadata": {},
   "source": [
    "s2['a']"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "__NB__: come abbiamo detto, Pandas è in grado di far corrispondere le righe sulla base delle etichette/indici; bisogna però fare attenzione a fare in modo che gli indici siano nello stesso formato (ad esempio, l'indice numerico 1 è diverso dalla stringa '1').",
   "id": "3d1a6c4fe03f368b"
  },
  {
   "cell_type": "code",
   "id": "ce53439b",
   "metadata": {},
   "source": [
    "s1 = pd.Series([0,1,2], index = [0,1,2])\n",
    "s2 = pd.Series([3,4,5], index = ['0','1','2'])\n",
    "s1+s2\n",
    "# non effettua l'addizione gli indici perché i primi sono numeri interi e i secondi stringhe"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c821004b",
   "metadata": {},
   "source": "Con il metodo `astype` si possono fare le dovute conversioni di tipo."
  },
  {
   "cell_type": "code",
   "id": "b8761d11",
   "metadata": {},
   "source": [
    "s2.index = s2.index.values.astype(int)\n",
    "s1+s2"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "410689d0",
   "metadata": {},
   "source": "### Reindicizzare e inserire valori mancanti"
  },
  {
   "cell_type": "code",
   "id": "6f013fee",
   "metadata": {},
   "source": [
    "s2 = s.copy()\n",
    "s2.reindex(['a', 'f'], fill_value = 0) # i valori mancanti verranno rimpiazzati con il valore di default 0"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "952772c2",
   "metadata": {},
   "source": [
    "s3 = pd.Series(['red', 'green', 'blue'], index = [0, 3, 5])\n",
    "s3"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "98b319c5",
   "metadata": {},
   "source": [
    "Dopo aver passato le nuove etichette come primo parametro, al metodo `reindex()` è possibile specificare il metodo con cui deve procedere alla sostituzione dei valori mancanti. <br>\n",
    "I due che vediamo noi sono:\n",
    "- _forward fill_, in cui i valori mancanti sono sostituiti con il valore esattamente precedente nella serie (NaN se non presente)\n",
    "- _backward fill_, in cui i valori mancanti sono sostiuiti con il valore esattamente successivo nella serie (NaN se non presente)"
   ]
  },
  {
   "cell_type": "code",
   "id": "3b4733d5",
   "metadata": {},
   "source": "s3.reindex(np.arange(0,7), method = 'ffill') # inizia a riempire sostituendo i valori mancati dall'inizio verso la fine della serie",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1026ad30",
   "metadata": {},
   "source": "s3.reindex(np.arange(0,7), method = 'bfill') # inizia a riempire sostituendo i valori mancanti dalla fine verso l'inizio della serie",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "0e95fd53",
   "metadata": {},
   "source": "### Riorganizzare e aggregare i dati"
  },
  {
   "cell_type": "code",
   "id": "508a8067",
   "metadata": {},
   "source": [
    "import datetime\n",
    "import yfinance as yf # libreria per scaricare dati da yahoo finance"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "cc6ee00f",
   "metadata": {},
   "source": [
    "start = datetime.datetime(2012, 1, 1)\n",
    "end = datetime.datetime(2012, 12, 30)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f31b8b3a",
   "metadata": {},
   "source": [
    "msft = yf.download('MSFT', start, end) # dati presi da yahoo finance relativi a microsoft anno 2012\n",
    "aapl = yf.download('AAPL', start, end) # dati presi da yahoo finance relativi a apple anno 2012\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "31ad53b8",
   "metadata": {},
   "source": [
    "msft.to_csv(\"msft.csv\")\n",
    "aapl.to_csv(\"aapl.csv\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6d2a37c1",
   "metadata": {},
   "source": [
    "msft.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "82985262",
   "metadata": {},
   "source": [
    "msft.tail()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ccaa7e3c",
   "metadata": {},
   "source": [
    "msft = pd.read_csv(\"msft.csv\", index_col = 0, parse_dates = True)\n",
    "aapl = pd.read_csv(\"aapl.csv\", index_col = 0, parse_dates = True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "094d327c",
   "metadata": {},
   "source": "msft[:3] # slicing dalla posizione 0 alla posizione 3 (esclusa), ovvero prendi i primi 3 elementi del DataFrame",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5d740625",
   "metadata": {},
   "source": "aapl[:3] # slicing dalla posizione 0 alla posizione 3 (esclusa), ovvero prendi i primi 3 elementi del DataFrame",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d2239334",
   "metadata": {},
   "source": [
    "### Concatenare i DF\n",
    "\n",
    "Prendiamo le due porzioni di DataFrame relative rispettivamente alla chiusura aggiustata di gennaio e febbraio 2012 di Microsoft."
   ]
  },
  {
   "cell_type": "code",
   "id": "f91d86c8",
   "metadata": {},
   "source": [
    "msftA01 = msft.loc['2012-01'][['Adj Close']]\n",
    "msftA02 = msft.loc['2012-02'][['Adj Close']]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "36850d7c",
   "metadata": {},
   "source": [
    "msftA01[:3]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "29532e73",
   "metadata": {},
   "source": [
    "msftA02[:3]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ca2759ec",
   "metadata": {},
   "source": "Vogliamo concatenare i due DataFrame (limitandoci alle prime 3 righe in questo caso) che in questo caso hanno indici diversi, usiamo quindi il metodo `concat()` a cui passiamo le porzioni di DataFrame da concatenare (sotto forma di lista)."
  },
  {
   "cell_type": "code",
   "id": "3971514b",
   "metadata": {},
   "source": [
    "pd.concat([msftA01.head(3),msftA02.head(3)])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "5c9cdc1b",
   "metadata": {},
   "source": "Proviamo ora a concatenare due DataFrame (limitandoci sempre alle prime 3 righe) che questa volta hanno gli stessi indici di riga; inoltre, prendiamo questa volta due porzioni di DataFrame che fanno riferimento ai due diversi titoli (sia Apple che Microsoft). "
  },
  {
   "cell_type": "code",
   "id": "8c04b08a",
   "metadata": {},
   "source": [
    "aaplA01 = aapl.loc['2012-01'][['Adj Close']]\n",
    "withDups = pd.concat([msftA01[:3], aaplA01[:3]])\n",
    "withDups"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2c4ec908",
   "metadata": {},
   "source": [
    "withDups.loc['2012-01-03']"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a2b19ae4",
   "metadata": {},
   "source": [
    "Applicando la concatenazione abbiamo perso l'informazione relativa al titolo a cui i prezzi si riferiscono. <br>\n",
    "Per ovviare al problema si può effettuare una concatenazione a indice multiplo, ottenendo così un DataFrame avente più di una colonna indice (in questo caso, il ticker e la data). <br>\n",
    "__PER CAPIRE__: prima l'indice era solo la data, la quale non ci permetteva di distinguere a quale titolo il prezzo fosse riferito."
   ]
  },
  {
   "cell_type": "code",
   "id": "fa161376",
   "metadata": {},
   "source": [
    "closes = pd.concat([msftA01[:3], aaplA01[:3]], keys = ['MSFT','AAPL'])\n",
    "closes"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "0ecdf2c1",
   "metadata": {},
   "source": [
    "closes.loc['MSFT'][:3]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d45af38f",
   "metadata": {},
   "source": "La concatenazione può anche avvenire su più colonne."
  },
  {
   "cell_type": "code",
   "id": "b87ba452",
   "metadata": {},
   "source": [
    "msftAV = msft[['Adj Close','Volume']]\n",
    "aaplAV = aapl[['Adj Close', 'Volume']]\n",
    "pd.concat([msftAV,aaplAV])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "cd2003b3",
   "metadata": {},
   "source": [
    "Nel caso in cui i due DataFrame concatenati non dovessero avere le stesse colonne, Pandas effettua l'allineamento sulle etichette delle colonne in comune ai due DataFrame, mentre per le altre inserisce valori NaN laddove sono presenti celle aventi valore mancante.\n",
    "\n",
    "__PER CAPIRE__: nell'esempio vengono concatenati due DataFrame, il primo ha come colonne Adj Close e Volume, mentre il secondo ha soltanto la colonna Adj Close: in questo caso, Pandas fa corrispondere le due colonne Adj Close comuni ad entrambi i DataFrame e mette NaN in tutte le celle corrispondenti alla colonna Volume appartenenti alle righe del secondo DataFrame (dato che il secondo DataFrame ha il dato mancante nella colonna Volume, allora Pandas mette NaN)."
   ]
  },
  {
   "cell_type": "code",
   "id": "9fed312e",
   "metadata": {},
   "source": [
    "aaplA = aapl[['Adj Close']]\n",
    "pd.concat([msftAV, aaplA]).tail(10)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b28c44df",
   "metadata": {},
   "source": "Se invece vogliamo fare in modo che il risultato contenga soltanto ciò che i due DataFrame hanno in comune (intersezione), allora specifichiamo come parametro il metodo con cui deve essere fatto il join (la funzione assume quindi un comportamento simile a quello del JOIN in SQL)."
  },
  {
   "cell_type": "code",
   "id": "a0dbf93f",
   "metadata": {},
   "source": "pd.concat([msftAV, aaplA], join='inner') # viene presa solo la colonna Adj Close comune ad entrambi i df",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "469986cd",
   "metadata": {},
   "source": [
    "Anche in questo caso si può andare a modificare l'asse lungo il quale avviene il concatenamento: modificando l'asse lungo il quale avviene il concatenamento possiamo vedere le colonne affiancate.\n",
    "\n",
    "__PER CAPIRE__: invece che concatenare le righe del secondo DataFrame sotto quelle del primo DataFrame, esse vengono poste di fianco."
   ]
  },
  {
   "cell_type": "code",
   "id": "44f1bbef",
   "metadata": {},
   "source": [
    "msftA = msft[['Adj Close']]\n",
    "closes = pd.concat([msftA, aaplA], axis = 1)\n",
    "closes[:3]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "896111f7",
   "metadata": {},
   "source": [
    "closes = pd.concat([msftA, aaplA], axis = 1, keys = ['MSFT','AAPL'])\n",
    "closes[:3]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3b9bd1c7",
   "metadata": {},
   "source": [
    "pd.concat([msftAV[:5], aaplAV[:3]], axis = 1, keys = ['MSFT','AAPL'])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "93bd9ddb",
   "metadata": {},
   "source": "Si può anche concatenare le due serie ignorando l'indice."
  },
  {
   "cell_type": "code",
   "id": "e8c766de",
   "metadata": {},
   "source": [
    "pd.concat([msftAV[:3], aaplAV[:3]], ignore_index = True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d7c5e289",
   "metadata": {},
   "source": [
    "### Fondere i DataFrame\n",
    "\n",
    "La funzione `merge()` combina i dati basandosi sui valori di una colonna (chiave): a differenza del concatenamento, in cui i dati vengono semplicemente \"incollati\" lungo l'asse desiderato senza effetutare corrispondenze tra etichette o colonne, il merge è un'operazione che combina i dati provenienti da due diversi DataFrame sulla base della corrispondenza di una colonna (colonna chiave)."
   ]
  },
  {
   "cell_type": "code",
   "id": "06ec8c88",
   "metadata": {},
   "source": [
    "msftAR = msftA.reset_index() # DataFrame contenente i dati relativi alla chisura aggiustata giornaliera di Microsoft\n",
    "msftAR"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e4709628",
   "metadata": {},
   "source": [
    "msftVR = msft[['Volume']].reset_index() # DataFrame contenente i dati relativi al volume giornaliero di Microsoft\n",
    "msftVR"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "L'obiettivo del merge è quello di prendere i dati di questi due DataFrame ed unirli facendo combaciare la colonna chiave, che in questo caso è rappresenta dalla data: facendo combaciare le date, si ottiene un nuovo DataFrame in cui per ogni riga (ogni giorno) si ha il corrispondente dato relativo alla chiusura aggiustata e al volume scambiato.",
   "id": "fc350c63f89c2c7d"
  },
  {
   "cell_type": "code",
   "id": "66d47bee",
   "metadata": {},
   "source": [
    "msftCVR = pd.merge(msftAR, msftVR)\n",
    "msftCVR.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1edc8af5",
   "metadata": {},
   "source": [
    "Si nota facilmente la somiglianza di questa operazione con il JOIN SQL.\n",
    "Il funzionamento dei vari tipi di join pandas è simile a quello SQL:\n",
    "- left - usa le chiavi del df di sinistra (SQL LEFT-OUTER JOIN)\n",
    "- right - usa le chiavi del df a destra (SQL RISHT-OUTER JOIN)\n",
    "- outer - usa l'unione delle chiavi dei due df (SQL FULL OUTER JOIN)\n",
    "- inner - usa l'intersezione delle chiavi dei due df (SQL INNER JOIN)"
   ]
  },
  {
   "cell_type": "code",
   "id": "9d096317",
   "metadata": {},
   "source": [
    "msftAR0_5 = msftAR[0:5]\n",
    "msftAR0_5"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d92bf424",
   "metadata": {},
   "source": [
    "msftVR2_4 = msftVR[2:4]\n",
    "msftVR2_4"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e884a0bc",
   "metadata": {},
   "source": [
    "pd.merge(msftAR0_5, msftVR2_4)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a6acd31c",
   "metadata": {},
   "source": [
    "pd.merge(msftAR0_5, msftVR2_4, how = 'outer')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "__NB__: come in SQL, la tipologia di join applicata di default è l'inner join.",
   "id": "f94164d0bddf2058"
  },
  {
   "cell_type": "markdown",
   "id": "f647b41e",
   "metadata": {},
   "source": [
    "### Pivoting\n",
    "\n",
    "Il pivoting è una tecnica che consente di riformattare un DataFrame trasformando i valori di una colonna in nuove colonne e riorganizzando di conseguenza i dati.\n",
    "\n",
    "__PER CAPIRE__: il pivoting serve a trasformare i dati da un formato \"lungo\" ad un formato \"largo\" per poterli visualizzare e analizzare diversamente."
   ]
  },
  {
   "cell_type": "code",
   "id": "7ecc4cd7",
   "metadata": {},
   "source": [
    "msft.insert(0, 'Symbol', 'MSFT') # inserimento della colonna Symbol in posizione 0 con valore MSFT\n",
    "msft"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "aapl.insert(0, 'Symbol', 'AAPL') # inserimento della colonna Symbol in posizione 0 con valore AAPL\n",
    "aapl"
   ],
   "id": "124b03d0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "combined = pd.concat([msft, aapl]).sort_index() # concateniamo i due DataFrame e ordiniamo le righe sulla base della data\n",
    "combined"
   ],
   "id": "b7d814d93fe9847c",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "fd32ed24",
   "metadata": {},
   "source": [
    "s4p = combined.reset_index() # per praticità invece che avere la data come indice, manteniamo degli indici numerici ordinati\n",
    "s4p.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "raw",
   "id": "b7d9f5cf",
   "metadata": {},
   "source": "Vogliamo creare un nuovo DataFrame nel quale AAPL e MSFT siano i titoli di due colonne che contengono i rispettivi prezzi di chiusura."
  },
  {
   "cell_type": "code",
   "id": "a7f89710",
   "metadata": {},
   "source": [
    "closes= s4p.pivot(index = 'Date', columns = 'Symbol', values = 'Adj Close')\n",
    "closes.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "In questo modo effettuiamo il pivoting specificando la colonna che deve fungere da indice, la colonna i cui valori devono diventare i titoli delle nuove colonne e la colonna da cui attingere i valori da visualizzare. <br>",
   "id": "5e22e38024e9796e"
  },
  {
   "cell_type": "markdown",
   "id": "53e94f56",
   "metadata": {},
   "source": [
    "### Stacking e unstacking\n",
    "Si possono usare i comandi `stack()` e `unstack()` per passare dalla forma \"larga\" (prodotta dal pivoting) a quella \"lunga\" (smontando quindi il pivoting) e viceversa."
   ]
  },
  {
   "cell_type": "code",
   "id": "cd10b696",
   "metadata": {},
   "source": [
    "stackedCloses = closes.stack()\n",
    "stackedCloses"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f25592c4",
   "metadata": {},
   "source": [
    "stackedCloses.loc['2012-01-03','AAPL']"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5b63d804",
   "metadata": {},
   "source": [
    "stackedCloses.loc['2012-08-31']"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "fe45e4b4",
   "metadata": {},
   "source": [
    "stackedCloses.loc[:,'MSFT']"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c00cc251",
   "metadata": {},
   "source": [
    "unstackedCloses = stackedCloses.unstack()\n",
    "unstackedCloses.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "dd19740a",
   "metadata": {},
   "source": "### Melting\n"
  },
  {
   "cell_type": "code",
   "id": "1b752b8e",
   "metadata": {},
   "source": [
    "melted = pd.melt(s4p, id_vars = ['Date', 'Symbol'])\n",
    "melted.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ec73e011",
   "metadata": {},
   "source": [
    "melted[(melted.Date == '2012-01-03') & (melted.Symbol == 'MSFT')]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f3494933",
   "metadata": {},
   "source": "### Split - Combine - Apply"
  },
  {
   "cell_type": "code",
   "id": "c6f71d0e",
   "metadata": {},
   "source": [
    "s4g = combined[['Symbol', 'Adj Close']].reset_index()\n",
    "s4g"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "067206d0",
   "metadata": {},
   "source": [
    "s4g.insert(1,'Year',pd.DatetimeIndex(s4g['Date']).year)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "45f19796",
   "metadata": {},
   "source": [
    "s4g.insert(2,'Month',pd.DatetimeIndex(s4g['Date']).month)\n",
    "s4g"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8ef07b07",
   "metadata": {},
   "source": [
    "s4g.groupby('Symbol')"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
